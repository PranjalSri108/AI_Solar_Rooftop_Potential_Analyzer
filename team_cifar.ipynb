{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AI Solar Roof Potential Analyzer Web App\n",
    "\n",
    "This Streamlit web application analyzes solar roof potential using satellite imagery. Key features include:\n",
    "\n",
    "- Upload and crop satellite images of rooftops\n",
    "- Generate heat maps of suitable areas for solar panels using a pre-trained segmentation model\n",
    "- Calculate potential solar energy production based on roof area and location\n",
    "- Visualize monthly energy production and cost savings\n",
    "- Compare current electricity bills with potential solar savings\n",
    "\n",
    "The app provides an interactive interface for users to assess the viability of solar panel installation on their roofs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title('AI Solar Roof Potential Analyzer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 320\n",
    "PIXEL_AREA = 0.2\n",
    "PANEL_EFFICIENCY = 0.15\n",
    "TEMP_COEF = -0.005\n",
    "ELEC_RATE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_WEBSITE = 'https://earthexplorer.usgs.gov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "ENCODER = 'timm-efficientnet-b4'\n",
    "WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel, self).__init__()\n",
    "        self.backbone = smp.Unet(\n",
    "            encoder_name=ENCODER,\n",
    "            encoder_weights=WEIGHTS,\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation=None\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.backbone(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = SegmentationModel()\n",
    "    model.load_state_dict(torch.load('vgg_best-model.pt', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    aug = A.Compose([A.Resize(IMG_SIZE, IMG_SIZE)])\n",
    "    augmented = aug(image=image)\n",
    "    image = augmented['image']\n",
    "    image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "    image = torch.Tensor(image) / 255.0\n",
    "    return image.unsqueeze(0), augmented['image'].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def postprocess_mask(mask, original_size):\n",
    "    mask = mask.squeeze().cpu().numpy()\n",
    "    mask = cv2.resize(mask, original_size, interpolation=cv2.INTER_NEAREST)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def roof_area_calculate(mask):\n",
    "    roof_area = PIXEL_AREA * np.sum(np.any(mask != [0, 0, 0], axis=-1))\n",
    "    return roof_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def apply_heat_map(mask):\n",
    "    gradient = np.linspace(0, 1, mask.shape[1]) \n",
    "    gradient = np.tile(gradient, (mask.shape[0], 1))  \n",
    "\n",
    "    orange = np.array([255, 125, 0], dtype=np.uint8)\n",
    "    yellow = np.array([255, 255, 0], dtype=np.uint8)\n",
    "\n",
    "    colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "    for i in range(3):\n",
    "        colored_mask[:, :, i] = np.uint8((orange[i] * (1 - gradient) + yellow[i] * gradient) * mask)\n",
    "    return colored_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_states():\n",
    "    df = pd.read_csv('Datasets/solar_irradiance.csv')\n",
    "    return [state.title() for state in df.iloc[:, 0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_temperature_data():\n",
    "    return pd.read_csv('Datasets/temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_irradiance_data():\n",
    "    return pd.read_csv('Datasets/solar_irradiance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "temperature_df = load_temperature_data()\n",
    "irradiance_df = load_irradiance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_monthly_solar_energy(state, roof_area):\n",
    "    state_temp = temperature_df[temperature_df.iloc[:, 0] == state.upper()].iloc[0, 1:].tolist()\n",
    "    state_irrd = irradiance_df[irradiance_df.iloc[:, 0] == state.upper()].iloc[0, 1:].tolist()\n",
    "    \n",
    "    monthly_energy = []\n",
    "    for temp, irrd in zip(state_temp, state_irrd):\n",
    "        eff = PANEL_EFFICIENCY * (1 + TEMP_COEF * (temp - 25))\n",
    "        solar_energy = irrd * eff * roof_area * 30  # kWh\n",
    "        monthly_energy.append(solar_energy//100)\n",
    "    \n",
    "    return monthly_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    states = load_states()\n",
    "\n",
    "    with st.sidebar:\n",
    "\n",
    "        st.header(\"Share your Contact info: \")\n",
    "\n",
    "        st.sidebar.image(\"satellite.jpg\", use_column_width=True)\n",
    "\n",
    "        user_name = st.text_input(\"Enter your name:\")\n",
    "\n",
    "        col1, col2 = st.columns([2,1])\n",
    "\n",
    "        with col1:\n",
    "            age = st.slider(\"Age: \", 1, 100, 50)\n",
    "        with col2:\n",
    "            gender = [\"M\", \"F\"]\n",
    "            gender = st.selectbox(\"Gender\", gender)\n",
    "\n",
    "        user_info = st.text_input(\"Enter your mail id:\")\n",
    "\n",
    "        if st.button(\"Submit\"):\n",
    "            i = 0\n",
    "\n",
    "    st.success('We are here to make Bharat a GREEN country')\n",
    "\n",
    "    st.markdown(\"\"\"---\"\"\")\n",
    "   \n",
    "    col1, col2 = st.columns([3,1])\n",
    "\n",
    "    with col1:\n",
    "      st.subheader(\"Get satellite imagery of your rooftop :satellite::\")\n",
    "\n",
    "    with col2:\n",
    "      if st.button(\"USGS Earth Explorer\"):\n",
    "        webbrowser.open_new_tab(USGS_WEBSITE)\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        selected_state = st.selectbox(\"Select a State\", states)\n",
    "\n",
    "    with col2:\n",
    "        current_bill = st.number_input('Enter your Current Annual Electric bill (in Rs.)', min_value=0, max_value=10000000, value=0)\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Upload aerial imagery\", type=[\"jpg\", \"jpeg\", \"png\", \"tif\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        image = Image.open(uploaded_file)\n",
    "        width, height = image.size\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col2:\n",
    "            st.subheader(\"Crop Parameters\")\n",
    "            left = st.slider(\"Left\", 0, width, 0)\n",
    "            top = st.slider(\"Top\", 0, height, 0)\n",
    "            right = st.slider(\"Right\", left, width, width)\n",
    "            bottom = st.slider(\"Bottom\", top, height, height)\n",
    "\n",
    "        with col1:\n",
    "            st.subheader(\"Image Preview\")\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            ax.imshow(np.array(image))\n",
    "            rect = plt.Rectangle((left, top), right - left, bottom - top,\n",
    "                                 fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(rect)\n",
    "            ax.axis('off')\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        if st.button(\"Generate Segmentation Mask\"):\n",
    "            cropped_image = image.crop((left, top, right, bottom))\n",
    "            image_np = np.array(cropped_image)\n",
    "            preprocessed_image, original_size = preprocess_image(image_np)\n",
    "\n",
    "            with st.spinner('Generating heatmap...'):\n",
    "                time.sleep(2)  # Simulate some processing time\n",
    "                with torch.no_grad():\n",
    "                    logits = model(preprocessed_image)\n",
    "                    pred_mask = torch.sigmoid(logits)\n",
    "                    pred_mask = (pred_mask > 0.5).float()\n",
    "\n",
    "                resized_mask = postprocess_mask(pred_mask, (right - left, bottom - top))\n",
    "                heat_map_mask = apply_heat_map(resized_mask)\n",
    "\n",
    "                roof_area = roof_area_calculate(heat_map_mask)\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    st.subheader(\"Rooftop\")\n",
    "                    st.image(cropped_image, use_column_width=True)\n",
    "                with col2:\n",
    "                    st.subheader(\"Generated Heatmap\")\n",
    "                    st.image(heat_map_mask, use_column_width=True, clamp=True)\n",
    "\n",
    "                st.info(f\"Roof Area: {roof_area:.2f} sq. m\")\n",
    "\n",
    "                monthly_energy = calculate_monthly_solar_energy(selected_state, roof_area)\n",
    "                \n",
    "                months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "                \n",
    "                \n",
    "                fig = go.Figure()\n",
    "                fig.add_trace(go.Scatter(x=months, y=monthly_energy, mode='lines+markers', name='Energy Production'))\n",
    "                fig.update_layout(\n",
    "                    title=f'Monthly Solar Energy Production of your house',\n",
    "                    xaxis_title='Months',\n",
    "                    yaxis_title='Energy Production (kWh)',\n",
    "                    height=350\n",
    "                )\n",
    "\n",
    "                st.plotly_chart(fig)\n",
    "\n",
    "                total_annual_energy = sum(monthly_energy)\n",
    "\n",
    "                if current_bill > 0:\n",
    "                    energy_savings = total_annual_energy * ELEC_RATE\n",
    "\n",
    "                    monthly_savings = [energy * ELEC_RATE for energy in monthly_energy]\n",
    "                    monthly_bill = [(current_bill / 12) - (savings) for savings in monthly_savings]\n",
    "\n",
    "                    fig = go.Figure()\n",
    "\n",
    "                    fig.add_trace(go.Scatter(\n",
    "                       x=months,\n",
    "                       y=[current_bill / 12] * len(months),\n",
    "                       mode='lines',\n",
    "                       name='Current Monthly Bill',\n",
    "                       line=dict(color='red', width=2, dash='dash') \n",
    "                    ))\n",
    "\n",
    "                    fig.add_trace(go.Scatter(\n",
    "                        x=months,\n",
    "                        y=monthly_bill,\n",
    "                        mode='lines+markers',\n",
    "                        name='Solar Monthly Bill',\n",
    "                        marker=dict(color='green', size=10),  \n",
    "                        line=dict(color='green', width=2) \n",
    "                    ))\n",
    "\n",
    "                    fig.update_layout(\n",
    "                        title=f'Monthly Bill After Solar Savings of you house',\n",
    "                        xaxis_title='Months',\n",
    "                        yaxis_title='Monthly Bill (Rs.)',\n",
    "                        height=300\n",
    "                    )\n",
    "\n",
    "                    st.plotly_chart(fig)\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "\n",
    "                with col1:            \n",
    "                  x = ['Current Bill', 'Solar Bill']\n",
    "                  y = [current_bill, energy_savings]\n",
    "\n",
    "                  fig = go.Figure()\n",
    "\n",
    "                  fig.add_trace(go.Bar(\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    name='Data',\n",
    "                    marker=dict(color='orange') \n",
    "                  ))\n",
    "\n",
    "                  fig.update_layout(\n",
    "                    title='Annual Electricity Bill',\n",
    "                    xaxis_title='',\n",
    "                    yaxis_title='Electric Bill',\n",
    "                    height=500\n",
    "                  )\n",
    "\n",
    "                  st.plotly_chart(fig)\n",
    "\n",
    "                with col2:\n",
    "                  st.info(\n",
    "                          f\"\"\"\n",
    "                          Your State: {selected_state}\n",
    "\n",
    "                          Your Roof Area: {roof_area:.2f} sq. m\n",
    "\n",
    "                          Total Solar Panel area: {(roof_area*0.8):.2f} sq. m\n",
    "\n",
    "                          Total Annual Solar Energy Production: {total_annual_energy:.2f} kWh\n",
    "                          \"\"\")\n",
    "                  \n",
    "                  st.success(f\"Estimated Annual Energy Savings: Rs. {(current_bill - energy_savings):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Rooftop Segmentation Model Training\n",
    "\n",
    "This script trains a deep learning model for rooftop segmentation in satellite imagery. Key components include:\n",
    "\n",
    "- Data loading and cleaning from CSV file\n",
    "- Image augmentation using albumentations library\n",
    "- Custom dataset and dataloader creation\n",
    "- U-Net model implementation using segmentation_models_pytorch\n",
    "- Training loop with learning rate scheduling\n",
    "- Model evaluation and visualization of results\n",
    "\n",
    "The trained model can be used to identify suitable areas for solar panel installation in satellite images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/robosobo/solar_rooftop/Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'Datasets/solar_train.csv'\n",
    "DATA_DIR = 'Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 15 \n",
    "IMG_SIZE = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'timm-efficientnet-b3'\n",
    "WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    def fix_path(path):\n",
    "        if path.startswith('images') and '_label' in path:\n",
    "            return path.replace('images', 'masks', 1)\n",
    "        return path\n",
    "\n",
    "    df['images'] = df['images'].apply(fix_path)\n",
    "    df['masks'] = df['masks'].apply(fix_path)\n",
    "    \n",
    "    df = df[df['images'].apply(lambda x: os.path.exists(os.path.join(DATA_DIR, x)))]\n",
    "    df = df[df['masks'].apply(lambda x: os.path.exists(os.path.join(DATA_DIR, x)))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Loading and cleaning dataset...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = clean_dataset(df)\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(\"Dataset loaded and cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(p=1),\n",
    "            A.RandomGamma(p=1),\n",
    "        ], p=0.5),\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_valid_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, df, augmentations):\n",
    "        self.df = df\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "\n",
    "            image_path = os.path.join(DATA_DIR, row.images)\n",
    "            mask_path = os.path.join(DATA_DIR, row.masks)\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if not os.path.exists(mask_path):\n",
    "                raise FileNotFoundError(f\"Mask file not found: {mask_path}\")\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"Failed to load mask: {mask_path}\")\n",
    "\n",
    "            mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "            if self.augmentations:\n",
    "                augmented = self.augmentations(image=image, mask=mask)\n",
    "                image = augmented['image']\n",
    "                mask = augmented['mask']\n",
    "\n",
    "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "            mask = np.transpose(mask, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "            image = torch.Tensor(image) / 255.0\n",
    "            mask = torch.round(torch.Tensor(mask) / 255.0)\n",
    "\n",
    "            return image, mask\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating datasets...\")\n",
    "trainset = SegmentationDataset(train_df, augmentations=get_train_augs())\n",
    "validset = SegmentationDataset(valid_df, augmentations=get_valid_augs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of trainset: {len(trainset)}')\n",
    "print(f'Length of validset: {len(validset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating data loaders...\")\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "validloader = DataLoader(validset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f'Total no. of batches in trainloader: {len(trainloader)}')\n",
    "print(f'Total no. of batches in validloader: {len(validloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel, self).__init__()\n",
    "        self.backbone = smp.Unet(\n",
    "            encoder_name=ENCODER,\n",
    "            encoder_weights=WEIGHTS,\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation=None\n",
    "        )\n",
    "\n",
    "    def forward(self, images, masks=None):\n",
    "        logits = self.backbone(images)\n",
    "\n",
    "        if masks is not None:\n",
    "            dice_loss = DiceLoss(mode='binary')(logits, masks)\n",
    "            bce_loss = nn.BCEWithLogitsLoss()(logits, masks)\n",
    "            focal_loss = FocalLoss(mode='binary')(logits, masks)\n",
    "            return logits, dice_loss + bce_loss + 0.5 * focal_loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Creating model...\")\n",
    "model = SegmentationModel().to(device)\n",
    "print(\"Model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader, model, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, masks in tqdm(dataloader, desc=\"Train\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(images, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eval_fn(dataloader, model):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc=\"Valid\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            logits, loss = model(images, masks)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating optimizer...\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "print(\"Optimizer created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating learning rate scheduler...\")\n",
    "scheduler = StepLR(optimizer, 15, gamma=0.1)\n",
    "print(\"Scheduler created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training loop...\")\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"Epoch {i+1}/{EPOCHS}\")\n",
    "    train_loss = train_fn(trainloader, model, optimizer)\n",
    "    valid_loss = eval_fn(validloader, model)\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "        print(\"SAVED MODEL\")\n",
    "        best_loss = valid_loss\n",
    "\n",
    "    print(f'Epoch: {i+1}, Train Loss: {train_loss:.6f}, Valid Loss: {valid_loss:.6f}, LR: {scheduler.get_last_lr()[0]}')\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"Starting visualization...\")\n",
    "idx = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best-model.pt', map_location=device))\n",
    "image, mask = validset[idx]\n",
    "image, mask = image.to(device), mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_mask = model(image.unsqueeze(0))\n",
    "pred_mask = torch.sigmoid(logits_mask)\n",
    "pred_mask = (pred_mask > 0.5) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.cpu()\n",
    "mask = mask.cpu()\n",
    "pred_mask = pred_mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask.squeeze(), cmap='gray')\n",
    "plt.title('Ground Truth Mask')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(pred_mask.squeeze().detach().numpy(), cmap='gray')\n",
    "plt.title('Predicted Mask')\n",
    "plt.show()\n",
    "print(\"Visualization completed.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
